{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0294b40b",
   "metadata": {},
   "source": [
    "# Predicción del precio de alquiler de la vivienda en la ciudad de Barcelona\n",
    "\n",
    "Descripción del dataset:\n",
    "\n",
    "|Columna|Descripción|Key|\n",
    "|--|--|--|\n",
    "|id|Identificador numérico de la vivienda||\n",
    "|price|Precio de mercado de la vivienda||\n",
    "|currency|Moneda|Euros / Mes|\n",
    "|latitude|Latitud de las coordenadas geográficas de la vivienda||\n",
    "|longitude|Longitud de las coordenadas geográficas de la vivienda||\n",
    "|sq_meters|Metros cuadrados de la vivienda||\n",
    "|sq_meters_built|Metros cuadrados construídos de la vivienda||\n",
    "|rooms|Número de habitaciones||\n",
    "|bathrooms|Número de baños||\n",
    "|balcony|Indicador si la vivienda tiene balcón|1, 0|\n",
    "|terrace|Indicador si la vivienda tiene terraza|1, 0|\n",
    "|exterior|Indicador si la vivienda tiene una orientación exterior o interior en el edificio|1, 0|\n",
    "|orientation|Orientación principal de la vivienda|norte, sur, este, oeste|\n",
    "|floor|Piso de la vivienda||\n",
    "|rooftop|Indicador si la vivienda es un ático|1, 0|\n",
    "|elevator|Indicador si el edificio de la vivienda tiene ascensor|1, 0|\n",
    "|doorman|Indicador si el edificio tiene portero|1,0|\n",
    "|pool|Indicador si la vivienda cuenta con piscina o derecho de uso de piscina|1,0|\n",
    "|ac|Indicador si tiene aire acondicionado|1,0|\n",
    "|heating|Indicador si tiene calefacción|bomba, electric, gas, individual|\n",
    "|year_built|Año de construcción||\n",
    "|quality|Indicador de calidad de la vivienda|2 - En buen estado|\n",
    "|city|Ciudad de la vivienda||\n",
    "|neighborhood|Barrio de la vivienda||\n",
    "|dist_city_center|Distancia en kilómetros al centro de la ciudad||\n",
    "|furniture|Indicador si la vivienda cuenta con mobiliario|1: Sin Equipar; 2: Cocina Equipada; 3: Amueblado|\n",
    "|garage|Indicador si la vivienda tiene garage|1, 0|\n",
    "|property_type|Tipo de vivienda||\n",
    "|garden|Indicador si la vivienda cuenta con jardín|1,0|\n",
    "|closest_station|Nombre de la estación de metro más cercana||\n",
    "|dist_closest_station|Distancia en kilómetros a la estación de metro más cercana||\n",
    "|created_at|Fecha de creación del anuncio||\n",
    "|last_seen|Fecha última en la que el anuncio fue publicado en la web||\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8e4f57",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "En éste punto queremos entender qué datos tenemos disponibles. Para ello realizaremos los siguientes puntos:\n",
    "\n",
    "- Estadística descriptiva y calidad general de los datos: ¿Debemos hacer limpieza de los datos?, ¿Nos sirven todas las columnas?, ¿Nos sirven todas las instancias?, ¿Cómo debemos tratar los null values?\n",
    "- Visualizaciones y análisis que ayuden a entender la distribución de las variables continuas y categorías independientemente: ¿Qué distribuciones siguen las variables continuas?, ¿Qué proporción de instancias tenemos para las variables categóricas?\n",
    "- Visualizaciones y análisis que ayuden a entender la relación entre los atributos y la variable objetivo price: ¿Qué relación tienen las variables continuas con la variable objetivo price?, ¿Y las cariables categóricas?\n",
    "- Alteración y creación de nuevas variables: ¿Podemos generar nuevas variables que se adapten más a nuestro objetivo que las que tenemos actualmente?\n",
    "- Visualizaciones y análisis que ayuden a entender la posible correlación entre variables: ¿Cómo están relacionadas entre sí las variables interesantes para nuestro dominio?, ¿Debemos tener algún tipo de cuidado al respecto?\n",
    "\n",
    "**Objetivos de éste punto:**\n",
    "\n",
    "- Familiarizarnos con el dataset\n",
    "- Generar un dataframe limpio, con las variables útiles para entrenar los modelos\n",
    "- Entender qué posibles variables estén correlacionadas para evitar un sobreentrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdd18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3960b5a8",
   "metadata": {},
   "source": [
    "#### Carga de librerías y dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692ed37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library load\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting library\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Funciones para hacer cálculo estadístico\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# sklearn packages\n",
    "from sklearn.preprocessing import StandardScaler # Análisis de PCA\n",
    "from sklearn import metrics # Calcula métricas para un modelo\n",
    "from sklearn import tree # Cálculo de decision trees\n",
    "from sklearn.tree import DecisionTreeClassifier # Generación de modelos de decision tree\n",
    "from sklearn.ensemble import BaggingClassifier # Generación de modelos de bagging\n",
    "from sklearn.ensemble import RandomForestClassifier # Generación de modelo de random forest\n",
    "from sklearn.model_selection import train_test_split # Hace split entre training y testing\n",
    "from sklearn.model_selection import cross_validate # trains model with cross validation\n",
    "from sklearn.model_selection import GridSearchCV # Optimización de hiperparámetros para un modelo\n",
    "\n",
    "# Confusion matrix viz\n",
    "from mlxtend.evaluate import confusion_matrix # Calcula la matriz de confusion \n",
    "from mlxtend.plotting import plot_confusion_matrix #plot de la matriz de confusión\n",
    "\n",
    "# Ignoring warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #ignora los errores en el notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47276ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('input/processed_renting_Barcelona.csv', delimiter = ',')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475c04dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los posibles resultados que queráis\n",
    "raw_data.to_csv(raw_data, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de62efc",
   "metadata": {},
   "source": [
    "#### Estadística descriptiva y calidad general de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a30a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones útiles:\n",
    "raw_data.describe() # Equivalente a función summary\n",
    "raw_data.columns # Enumera las columnas del dataset\n",
    "raw_data.isnull().sum() / len(raw_data) # Calcula la proporción de null values sobre todas las variables\n",
    "raw_data.drop(['column_name'], axis=1) # Retira columnas que no nos sean útiles en el dataset\n",
    "raw_data['column_name'].fillna(0, inplace = True) # Sustituye los Null values de una columna por 0. Podemos cambiar el 0 por cualquier otro valor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dcac17",
   "metadata": {},
   "source": [
    "#### Visualizaciones y análisis que ayuden a entender la distribución de las variables continuas y categorías independientemente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas para entender la distribución de las variables\n",
    "raw_data.hist(bins=20, figsize=(25, 20))\n",
    "# Para variables categóricas podemos hacer la función groupby\n",
    "raw_data[['column_name', 'price']].groupby('column_name').agg(\n",
    "    # Number of instances per category\n",
    "    category_count=('price', \"count\"),\n",
    "    # Mean price\n",
    "    mean_price=('price', \"mean\"),\n",
    "    # Median price\n",
    "    median_price=('price', \"median\"),\n",
    "    # Min price\n",
    "    min_price=('price', min),\n",
    "    # Max price\n",
    "    max_price=('price', max),\n",
    "    # Standard deviation\n",
    "    stantard_deviation=('price', \"std\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6a2a41",
   "metadata": {},
   "source": [
    "#### Visualizaciones y análisis que ayuden a entender la relación entre las variables categóricas y la variable objetivo price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7600cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ANOVA para \n",
    "model = ols('price ~ column_name', data=raw_data).fit()\n",
    "aov_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Scatter matrix, similar a la función pairs. Cuidado que solo sive para variables numéricas\n",
    "pd.plotting.scatter_matrix(raw_data, alpha=0.2, figsize=(20, 20), diagonal='kde')\n",
    "\n",
    "# Análisis de PCA. Cuidado que solo sive para variables numéricas y que hay que retirar la variable objetivo\n",
    "StandardScaler().fit_transform(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616d00d",
   "metadata": {},
   "source": [
    "#### Alteración y creación de nuevas variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed1a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_numerico =  raw_data[['price', 'sq_meters_built', 'dist_city_center']]\n",
    "dataset_numerico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8292729",
   "metadata": {},
   "source": [
    "#### Visualizaciones y análisis que ayuden a entender la posible correlación entre variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c9e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de correlación\n",
    "corrMatrix = raw_data.corr()\n",
    "# Visualización de la matriz de correlación\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674db2a4",
   "metadata": {},
   "source": [
    "### Modelo de Bagging\n",
    "\n",
    "En éste punto crearemos nuestro primer modelo de bagging. Para ello realizaremos los siguientes puntos:\n",
    "\n",
    "- Selección de la métrica de optimización: ¿Qué métrica debemos utilizar para optimizar y valorar la calidad de nuestros modelos?\n",
    "- Split del dataset en training y test: ¿Cómo debemos separar los datos para entrenar y validar nuestro modelo?\n",
    "- Optimización de hiperparámetros mediante Cross Validation: ¿Qué hiperparámetros deberíamos utilizar para entrenar nuestro modelo?\n",
    "- Entrenamiento del modelo y análisis de los resultados: ¿Es bueno nuestro modelo?\n",
    "\n",
    "**Objetivos de éste punto:**\n",
    "\n",
    "- Definir cómo mediremos los resultados de nuestro modelo\n",
    "- Generar y entrenar un modelo de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4df073",
   "metadata": {},
   "source": [
    "#### Selección de la métrica de optimización\n",
    "\n",
    "- Tipos de scoring metrics: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75316904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "321fa5dc",
   "metadata": {},
   "source": [
    "#### Split del dataset en training y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffb2102",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_numerico.drop(['price'], axis = 1)\n",
    "y = dataset_numerico[['price']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57394d4",
   "metadata": {},
   "source": [
    "#### Optimización de hiperparámetros mediante Cross Validation\n",
    "\n",
    "- Decision tree classifier: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "- Bagging classifier: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21da4e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we enumerate the values to try\n",
    "parameters = [{\"max_depth\":[2,3,4,5,6,7,9,10,12,15], \"min_samples_split\":[2,5,10]}]\n",
    "\n",
    "#instantiate the classifier\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "\n",
    "# Grid search function\n",
    "grid_bag = GridSearchCV(cv = 10, estimator=decision_tree_model, param_grid=parameters, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a311069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we enumerate the values to try\n",
    "parameters = [{\"n_estimators\":[1,5,10,20,50,100,200]]\n",
    "\n",
    "#instantiate the classifier\n",
    "bagging_model = BaggingClassifier(decision_tree_model)\n",
    "\n",
    "# Grid search function\n",
    "grid_bag = GridSearchCV(cv = 10, estimator=bagging_model, param_grid=parameters, scoring=\"accuracy\")\n",
    "grid_bag.fit(X_train, y_train)\n",
    "grid_bag.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15427c16",
   "metadata": {},
   "source": [
    "#### Entrenamiento del modelo y análisis de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369ce1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo con los hiperpametros seleccionados en el punto anterior\n",
    "bag = BaggingClassifier(DecisionTreeClassifier(max_depth = n, min_samples_split = m), n_estimators = n)\n",
    "# Entrenamos el modelo con el dataset de entrenamiento mediante cross validation\n",
    "model = cross_validate(bag, X_train, y_train, xv = 10, scoring=\"accuracy\")\n",
    "# Generación de las predicciones para el dataset de testing\n",
    "y_pred = model.predict(X_test)\n",
    "#error rate\n",
    "error = 1.0 - metrics.accuracy_score(y_test, y_pred)\n",
    "# Plot de la matriz de confusión\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, y_pred, binary = False))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
