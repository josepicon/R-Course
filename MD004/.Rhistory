data = read.csv("https://raw.githubusercontent.com/josepicon/R-Course/main/MD004/customer_churn_data.csv", stringsAsFactors=F)
head(data, 10)
head(data, 5)
#checking the contents of the data
str(data)
summary(data)
is.null(data).sum()
is.null(data)
library("tidyr")
library("dplyr")
data  %>%
group_by(device)  %>%
summarize(user_id = n()
# Proportion of classes, we can see that class '0' has the majority of instances
round(prop.table(table(data$polarity))*100, digits = 1)
# Converting the polarity column from our 'data' dataframe into a factor datatype
data$type = factor(data$polarity)
#saving the data into a Large VCorpus for more efficient computation
data_corpus = VCorpus(VectorSource(data$review))
print(data_corpus)
#it seems that most of the data is already in lowercase, but we will...
# be transforming our text, converting uppercase letters into lowercase...
# in case there are any uppercase values
data_corpus_clean = tm_map(data_corpus, content_transformer(tolower))
# pulling the 2nd row with the previous and current data to confirm transformation
print(lapply(data_corpus[[2]][1], as.character))
print(lapply(data_corpus_clean[[2]][1], as.character))
# Remove numbers and stopwords
data_corpus_clean = tm_map(data_corpus_clean, removeNumbers)
data_corpus_clean = tm_map(data_corpus_clean, removeWords, stopwords())
# confirming changes have been made
print(lapply(data_corpus[[36]][1], as.character)) #contains numbers: '(12.0.0.15.14)'
print(lapply(data_corpus_clean[[36]][1], as.character)) #numbers have been removed
# Remove spaces from our data_corpus_clean dataset
data_corpus_clean = tm_map(data_corpus_clean, stemDocument)
# Visualización de la instancia antes y después de la transformación
print(lapply(data_corpus[[36]][1], as.character))
print(lapply(data_corpus_clean[[36]][1], as.character))
# creating a function that will replace puncuation with spaces
replacePunctuation = function(x) {gsub("[[:punct:]]", " ", x)}
# implementing replacePunctuation function
data_corpus_clean = tm_map(data_corpus_clean, replacePunctuation)
# confirming changes have been made
print(lapply(data_corpus[[36]][1], as.character))
print(lapply(data_corpus_clean[[35]][1], as.character))
#removing any whitespace from our data_corpus_clean dataset
data_corpus_clean <- tm_map(data_corpus_clean, stripWhitespace)
# Visualización de la instancia antes y después de la transformación
print(lapply(data_corpus[[36]][1], as.character))
print(lapply(data_corpus_clean[[36]][1], as.character))
# converting the dataframe into a plantextdocument
data_corpus_clean <- tm_map(data_corpus_clean, PlainTextDocument)
print(lapply(data_corpus[[1]][1], as.character))
print(lapply(data_corpus_clean[[1]][1], as.character))
#creating the Naive Bayes classification model
#creating a document-term matrix for our data_corpus_clean dataset
dtm =  DocumentTermMatrix(data_corpus_clean)
dtm
#reviewing the summary of our dataset
str(dtm)
#creating a vector of random numbers
set.seed(24358)
# creating a 75-25 spit for our train/test
inTrain <- createDataPartition(y = data$type
, p = .75
, list = FALSE
, times = 1)
# define the datasets between train and test
data.train<-data[inTrain,]
data.test<-data[-inTrain,]
# confirming splits
str(data.train)
str(data.test)
# creating test/train sets for our data_corpus_clean datasets
corpus.train = data_corpus_clean[inTrain]
corpus.test  = data_corpus_clean[-inTrain]
# creating test/train sets for our dtm datasets
dtm.train = dtm[inTrain, ]
dtm.test  = dtm[-inTrain, ]
# confirm in proportions are adequate
print("Training")
round(prop.table(table(data.train$polarity))*100, 2)
print("Test")
round(prop.table(table(data.test$polarity))*100, 2)
#creating a wordcloud using the 100 most used words
negative_review = subset(data.train, type == "0")
positive_review  = subset(data.train, type == "1")
wordcloud(data$review,
min.freq=100)
#creating a wordcloud with the words used in negative reviews
negative_review = subset(data.train, type == "0")
positive_review  = subset(data.train, type == "1")
wordcloud(negative_review$review,
max.words=20,
scale=c(10, 0, 10))
#creating a wordcloud with the words used in positive reviews
negative_review = subset(data.train, type == "0")
positive_review  = subset(data.train, type == "1")
wordcloud(positive_review$review,
max.words=20,
scale=c(10, 1, 10))
## finding the most requent terms from ourn dtm training set
freq_terms = findFreqTerms(dtm.train, 5)
#creating a test/train set with our most frequent terms
reduced_dtm.train = DocumentTermMatrix(corpus.train, list(dictionary=freq_terms))
reduced_dtm.test =  DocumentTermMatrix(corpus.test, list(dictionary=freq_terms))
ncol(reduced_dtm.train)
ncol(reduced_dtm.test)
#create a function that will convert the values of our polarity row into yes/no strings
convert_counts = function(x) {
x = ifelse(x > 0, 1, 0)
x = factor(x, levels = c(0, 1), labels=c("No", "Yes"))
return (x)
}
reduced_dtm.train = apply(reduced_dtm.train, MARGIN=2, convert_counts)
reduced_dtm.test  = apply(reduced_dtm.test, MARGIN=2, convert_counts)
# store our model in sms_classifier
sms_classifier = naiveBayes(reduced_dtm.train # training set
, data.train$type) # target training set
sms_test.predicted = predict(sms_classifier,  # predictions using our training set
reduced_dtm.test) # resulting prediction from our test set
# rendering confusion matrix
confusionMatrix(sms_test.predicted, data.test$type)
cat("we can see that our model predicts positive reviews 84% of the time, and negative reviews predicted correctly in 72% of instances ")
# visualizing the false postiives
data.test[(sms_test.predicted != data.test$type)
& (data.test$type == '0'),]
# visualizing the false negatives
data.test[(sms_test.predicted != data.test$type)
& (data.test$type == '1'),]
for (i in (1:10))
{
print(paste0("Laplace factor of ", as.character((i-1)/4)))
sms_classifier2 = naiveBayes(reduced_dtm.train,
data.train$type,
laplace = (i-1)/4)
sms_test.predicted2 = predict(sms_classifier2,
reduced_dtm.test)
print(confusionMatrix(sms_test.predicted2, data.test$type))
}
print("Based on the factors above,
it looks like the best performing Laplace factor is 0.25.
Where the accuracy of the model is 81%, and with a sensitivity of 85% and speceficity of 73%.
This seems like the most optimal model because this model has high probablity of correclty predicting both values,
compared with other Laplace factors, which have either a high specificity but a low sensitivity.
Other models that have a high sensitivity and specificy, such as Lapace factor 0.5,
have a lower accuracy score compared to 0.25. As a result, given the optimal levels of accuracy, sensitivity, and specificity,
I believe that the best optimzed model is at Laplace factor or 0.25")
data  %>%
group_by(device)  %>%
summarize(user_id = n()
summary(data)
library("tidyr")
library("dplyr")
data = read.csv("https://raw.githubusercontent.com/josepicon/R-Course/main/MD004/customer_churn_data.csv", stringsAsFactors=F)
head(data, 5)
#checking the contents of the data
str(data)
summary(data)
data  %>%
data  %>%
group_by(device)  %>%
summarize(user_id = n()
data  %>%
group_by(device)  %>%
summarize(user_id = n())
data  %>%
group_by(device)  %>%
summarize(user_id = n())
data  %>%
group_by(device)  %>%
summarize(user_id = n() %>%
arrange(desc(user_id)))
data  %>%
group_by(device)  %>%
summarize(user_id = n() %>%
arrange(desc(device))
data  %>%
group_by(device)  %>%
summarize(user_id = n() %>%
arrange(desc(device)))
data  %>%
group_by(device)  %>%
summarize(user_id = n() %>%
arrange(desc(user_id)))
phone_type <- data  %>%
group_by(device)  %>%
summarize(user_id = n()
phone_type <- data  %>%
group_by(device)  %>%
summarize(user_id = n())
View(data)
data  %>%
group_by(device)  %>%
summarize(user_id = n()), age = mean(age = n())
data  %>%
group_by(device)  %>%
summarize(user_id = n()) age = mean(age = n())
data  %>%
group_by(device)  %>%
summarize(user_id = n()), age = mean(age = n())
